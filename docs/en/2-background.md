---
layout: page
title: Background
permalink: /docs/en/background
key: docs-background
---



Sign language (SL) is the primary way for deaf or people with hearing loss to express themselves. Similar to various spoken languages, sign languages have their vocabularies and grammar. More importantly, diverse geographic regions usually have their native sign languages even though these regions share a commonly spoken language, such as America, Australia and the UK. To eliminate the communication barriers between the deaf and hearing communities, sign language translation (SLT) has been proposed to convert signs into spoken languages.


With the emerging deep learning techniques and large-scale sign language datasets, SLT has achieved promising progress recently. Researchers from various countries have constructed their sign language datasets and thus thrust SLT in their respective sign languages, such as American sign language (ASL), British sign language (BSL), Chinese sign language (CSL) and Germany sign language (DGS). 


However, to the best of our knowledge, there is no publicly available large-scale Auslan dataset for continuous sign translation. According to the Hearing Care Industry Association\footnote{\url{https://www.hcia.com.au/resources/HCIA.pdf}}, as of June 2015, one in six Australians had hearing loss affecting them and this proportion is expected to increase to one in four by 2050. Due to the societal inclusion and the regional nature of sign languages, Australian sign language (Auslan) datasets are inevitably and urgently needed in order to investigate automatic translation.
